{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm   # you may have to download it\n",
    "import hashing_lib as hl\n",
    "import time\n",
    "\n",
    "# In hashing_lib.py we imported BitVector, you may have to download it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Hashing task!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found the optimal number of hash functions $ k $, for a given size of the bloom filter $ m $ and number of elements $ n $, approximating $ k = \\frac{m}{n}ln2 $.\n",
    "\n",
    "We set $ p $ as the desired false positive probability and found that $ k = -\\log_2{p} $ is a good approximation.\n",
    "\n",
    "So setting $ p = 0.01 $ we have $ k = 6.64 \\simeq 6 $\n",
    "\n",
    "We found that in $ passwords1.txt $ there are $ 100\\,000\\,000 $ passwords so $ n = 100\\,000\\,000$.\n",
    "\n",
    "Now we can set the size $ m $ of the $ BloomFilter $, $\\ \\ $ $ m = -\\frac{n\\ln{p}}{\\ln^2{2}} \\simeq 958\\,505\\,837 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.01\n",
    "n = 100_000_000\n",
    "# we choose 958_505_837\n",
    "m = 958_505_837\n",
    "# number of hashing functions: k = 6\n",
    "k = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose to create a Class $ BloomFilter $ that take in input $ m $ and $ k $ precalculated. The class create a bit vector of size $ m $ and keep records of the number of passwords added in the filter and the number of probably duplicates found.\n",
    "\n",
    "In $ Less Hashing, Same Performance: Building a Better Bloom Filter $ we found a theorem that say we don't have to create 10 hashing functions (that are computational expensive), but instead we can use 2 independent hashing functions, $ h_1 $ and $ h_2 $ and iterate them using the following formula: $$ g_i(x) = h_1(x) + ih_2(x) + f(i) \\mod{m} $$\n",
    "with $ i $ in $ range(k) $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case we defined 2 simple hashing functions $ hash\\_1(string) $ and $ hash\\_2(string) $ and choose $ f(i) = i^2 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bloom_filter = hl.BloomFilter(m, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000000/100000000 [55:14<00:00, 30167.78it/s] \n",
      "100%|██████████| 39000000/39000000 [13:30<00:00, 48141.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time:  68.74856994549434 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 100,000,000 passwords in file1\n",
    "s = time.time()\n",
    "\n",
    "with tqdm(total = n) as pbar:\n",
    "    with open(\"../data/passwords1.txt\") as fin:\n",
    "        for line in fin:\n",
    "            line = line.strip()\n",
    "            bloom_filter.add_to_bloom(line)\n",
    "            pbar.update(1)\n",
    "            \n",
    "# 39,000,000 passwords in file1\n",
    "with open(\"../data/passwords2.txt\") as fin2:\n",
    "    with tqdm(total = 39_000_000) as pbar:\n",
    "        for line in fin2:\n",
    "            line = line.strip()\n",
    "            bloom_filter.check_in_bloom(line)\n",
    "            \n",
    "            pbar.update(1)\n",
    "\n",
    "print('Execution time: ', (time.time() - s)/60, 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements:  100000000\n",
      "Number of probably duplicates:  14253875\n",
      "Size of the filter:  958505837\n",
      "Number of hashing functions:  6\n",
      "False positives probability : 1.0 %\n"
     ]
    }
   ],
   "source": [
    "# print some stats of the bloom filter\n",
    "bloom_filter.print_stats()\n",
    "print('False positives probability :', p*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a set of passwords to see the number of actual duplicates.\n",
    "\n",
    "We use the set cause it doesn't allow duplicates, so knowing the number of total passwords we can calculate the number of duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This task is really heavy, if you want to see only the actual duplicates just run the last line\n",
    "We found out that the number of actual duplicates is $ 14\\,000\\,000 $, so we can use this and substract to the probably duplicates of the filter to find the real false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000000/100000000 [02:18<00:00, 722177.76it/s]\n",
      "100%|██████████| 39000000/39000000 [00:59<00:00, 657872.79it/s]\n"
     ]
    }
   ],
   "source": [
    "all_passwords = set([])\n",
    "with tqdm(total = n) as pbar:\n",
    "    with open(\"passwords1.txt\") as fin:\n",
    "        for line in fin:\n",
    "            # add pass to set\n",
    "            all_passwords.update([line.strip()])\n",
    "            pbar.update(1)\n",
    "            \n",
    "with open(\"passwords2.txt\") as fin2:\n",
    "    with tqdm(total = 39_000_000) as pbar2:\n",
    "        for line in fin2:\n",
    "            # add pass to set\n",
    "            all_passwords.update([line.strip()])\n",
    "            pbar2.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate actuall duplicates\n",
    "actual_duplicates = 139_000_000 - len(all_passwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14000000\n"
     ]
    }
   ],
   "source": [
    "print(actual_duplicates )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the number of the false positives is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253875"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bloom_filter.n_duplicates - 14_000_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "So out of $ 25\\,000\\,000 $ passwords only $ 253\\,875 $ results as false positive.\n",
    "\n",
    "We can state that our bloom filter with  $ 1\\% $ false positive probability worked."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
